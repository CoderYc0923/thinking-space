# 今日思考
## 查看了mediapipe相关的git项目 Sign-language-recognition-with-RNN-and-Mediapipe（利用 RNN 和 Mediapipe 进行手语识别） github: https://github.com/rabBit64/Sign-language-recognition-with-RNN-and-Mediapipe

## 目的
为了对之后手势相关项目做技术基础调研

## 该项目原理或思考过程
原理： 使用多手跟踪技术在桌面上创建输入视频的训练数据。使用深度学习模型进行手势识别时，可以通过 RNN 训练每帧的手部地标特征。

包括： 1.使用视频输入，而不是桌面上的网络摄像头，利用视频数据进行训练
2.预处理每帧每字的手部地标，并将其制作成一个 txt 文件

### 这里简单的阐述一下训练的步骤
1.建立手动跟踪框架
2.创建自己的训练数据
3.训练 RNN 模型